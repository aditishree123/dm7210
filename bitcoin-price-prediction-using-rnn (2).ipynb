{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing all the libraries\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom datetime import date\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom random import randint\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import GRU\nfrom keras.callbacks import EarlyStopping\nfrom keras import initializers\nfrom matplotlib import pyplot\nfrom datetime import datetime\nfrom matplotlib import pyplot as plt\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the dataset\ndata = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv')\ndata.isnull().values.any() #Will print False in case of no null values\ndata.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\ndata['date'] = pd.to_datetime(data['Timestamp'],unit='s').dt.date\ngroup = data.groupby('date')\nDaily_Price = group['Weighted_Price'].mean()\n\nDaily_Price.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Daily_Price.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import date\nd0 = date(2017, 1, 1)\nd1 = date(2020, 9, 9)\ndelta = d1 - d0\ndays_look = delta.days + 1\nprint(days_look)\n\nd0 = date(2019, 8, 21)\nd1 = date(2020, 9 , 14)\ndelta = d1 - d0\ndays_from_train = delta.days + 1\nprint(days_from_train)\n\nd0 = date(2020, 9, 9)\nd1 = date(2020, 9, 14)\ndelta = d1 - d0\ndays_from_end = delta.days + 1\nprint(days_from_end)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_train= Daily_Price[len(Daily_Price)-days_look-days_from_end:len(Daily_Price)-days_from_train]\ndf_test= Daily_Price[len(Daily_Price)-days_from_train:]\nprint(len(df_train), len(df_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"working_data = [df_train, df_test]\nworking_data = pd.concat(working_data)\n\nworking_data = working_data.reset_index()\nworking_data['date'] = pd.to_datetime(working_data['date'])\nworking_data = working_data.set_index('date')\nprint(working_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = sm.tsa.seasonal_decompose(working_data.Weighted_Price.values, period=60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(x = np.arange(0, len(s.trend), 1),y = s.trend,mode = 'lines',name = 'Trend',\n    line = dict(color = ('rgb(244, 146, 65)'), width = 4))\ntrace2 = go.Scatter(x = np.arange(0, len(s.seasonal), 1),y = s.seasonal,mode = 'lines',name = 'Seasonal',\n    line = dict(color = ('rgb(66, 244, 155)'), width = 2))\n\ntrace3 = go.Scatter(x = np.arange(0, len(s.resid), 1),y = s.resid,mode = 'lines',name = 'Residual',\n    line = dict(color = ('rgb(209, 244, 66)'), width = 2))\n\ntrace4 = go.Scatter(x = np.arange(0, len(s.observed), 1),y = s.observed,mode = 'lines',name = 'Observed',\n    line = dict(color = ('rgb(66, 134, 244)'), width = 2))\n\ndata = [trace1, trace2, trace3, trace4]\nlayout = dict(title = 'Seasonal decomposition', xaxis = dict(title = 'Time'), yaxis = dict(title = 'Price, USD'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='seasonal_decomposition')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = working_data[:-390]\ndf_test = working_data[-390:]\nprint(working_data.shape)\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_lookback(dataset, look_back=1):\n    X, Y = [], []\n    for i in range(len(dataset) - look_back):\n        a = dataset[i:(i + look_back), 0]\n        X.append(a)\n        Y.append(dataset[i + look_back, 0])\n    return np.array(X), np.array(Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-layer LSTM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntraining_set = df_train.values\ntraining_set = np.reshape(training_set, (len(training_set), 1))\ntest_set = df_test.values\ntest_set = np.reshape(test_set, (len(test_set), 1))\nfrom sklearn.preprocessing import MinMaxScaler\n#scale datasets\nscaler = MinMaxScaler()\ntraining_set = scaler.fit_transform(training_set)\ntest_set = scaler.transform(test_set)\n\n# create datasets which are suitable for time series forecasting\nlook_back = 1\nX_train, Y_train = create_lookback(training_set, look_back)\nX_test, Y_test = create_lookback(test_set, look_back)\n\n # reshape datasets so that they will be ok for the requirements of the LSTM model in Keras\nX_train = np.reshape(X_train, (len(X_train), 1, X_train.shape[1]))\nX_test = np.reshape(X_test, (len(X_test), 1, X_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializing 1-layer LSTM model\nregressor = Sequential()\n\n# Adding the input layer and the LSTM layer\nregressor.add(LSTM(units = 4, activation = 'sigmoid', input_shape = (X_train.shape[1],X_train.shape[2])))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nhistory=regressor.fit(X_train, Y_train, epochs=100, batch_size=15, shuffle=False,\n                    validation_data=(X_test, Y_test),\n                    callbacks = [EarlyStopping(monitor='val_loss', min_delta=5e-5, patience=20, verbose=1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    x = np.arange(0, len(history.history['loss']), 1),\n    y = history.history['loss'],\n    mode = 'lines',\n    name = 'Train loss',\n    line = dict(color=('rgb(66, 244, 155)'), width=2, dash='dash')\n)\ntrace2 = go.Scatter(\n    x = np.arange(0, len(history.history['val_loss']), 1),\n    y = history.history['val_loss'],\n    mode = 'lines',\n    name = 'Test loss',\n    line = dict(color=('rgb(244, 146, 65)'), width=2)\n)\n\ndata = [trace1, trace2]\nlayout = dict(title = 'Train and Test Loss during training',\n              xaxis = dict(title = 'Epoch number'), yaxis = dict(title = 'Loss'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='training_process')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add one additional data point to align shapes of the predictions and true labels\nprint(X_test.shape)\nprint(working_data.shape)\ny=scaler.transform(working_data.iloc[-1][0].reshape(1,-1))\nprint(y.shape)\nX_test = np.append(X_test, y)\nX_test = np.reshape(X_test, (len(X_test), 1, 1))\nprint(X_test.shape)\n# get predictions and then make some transformations to be able to calculate RMSE properly in USD\nprediction = regressor.predict(X_test)\nprediction_inverse = scaler.inverse_transform(prediction.reshape(-1, 1))\nY_test_inverse = scaler.inverse_transform(Y_test.reshape(-1, 1))\nprediction2_inverse = np.array(prediction_inverse[:,0][1:])\nY_test2_inverse = np.array(Y_test_inverse[:,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    x = np.arange(0, len(prediction2_inverse), 1),\n    y = prediction2_inverse,\n    mode = 'lines',\n    name = 'Predicted labels',\n    line = dict(color=('rgb(244, 146, 65)'), width=2)\n)\ntrace2 = go.Scatter(\n    x = np.arange(0, len(Y_test2_inverse), 1),\n    y = Y_test2_inverse,\n    mode = 'lines',\n    name = 'True labels',\n    line = dict(color=('rgb(66, 244, 155)'), width=2)\n)\n\ndata = [trace1, trace2]\nlayout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted',\n             xaxis = dict(title = 'Day number'), yaxis = dict(title = 'Price, USD'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='results_demonstrating0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_Dates = Daily_Price[len(Daily_Price)-days_from_train:].index\n\ntrace1 = go.Scatter(x=Test_Dates, y=Y_test2_inverse, name= 'Actual Price',\n                   line = dict(color = ('rgb(66, 244, 155)'),width = 2))\ntrace2 = go.Scatter(x=Test_Dates, y=prediction2_inverse, name= 'Predicted Price',\n                   line = dict(color = ('rgb(244, 146, 65)'),width = 2))\ndata = [trace1, trace2]\nlayout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted, by dates',\n             xaxis = dict(title = 'Date'), yaxis = dict(title = 'Price, USD'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='results_demonstrating1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2-layer LSTM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntraining_set = df_train.values\ntraining_set = np.reshape(training_set, (len(training_set), 1))\ntest_set = df_test.values\ntest_set = np.reshape(test_set, (len(test_set), 1))\nfrom sklearn.preprocessing import MinMaxScaler\n#scale datasets\nscaler = MinMaxScaler()\ntraining_set = scaler.fit_transform(training_set)\ntest_set = scaler.transform(test_set)\n\n# create datasets which are suitable for time series forecasting\nlook_back = 1\nX_train, Y_train = create_lookback(training_set, look_back)\nX_test, Y_test = create_lookback(test_set, look_back)\n\n # reshape datasets so that they will be ok for the requirements of the LSTM model in Keras\nX_train = np.reshape(X_train, (len(X_train), 1, X_train.shape[1]))\nX_test = np.reshape(X_test, (len(X_test), 1, X_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize sequential model, add 2 stacked LSTM layers and densely connected output neuron\nmodel = Sequential()\nmodel.add(LSTM(256, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(LSTM(256))\nmodel.add(Dense(1))\n\n# compile and fit the model\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory = model.fit(X_train, Y_train, epochs=100, batch_size=16, shuffle=False,\n                    validation_data=(X_test, Y_test),\n                    callbacks = [EarlyStopping(monitor='val_loss', min_delta=5e-5, patience=20, verbose=1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    x = np.arange(0, len(history.history['loss']), 1),\n    y = history.history['loss'],\n    mode = 'lines',\n    name = 'Train loss',\n    line = dict(color=('rgb(66, 244, 155)'), width=2, dash='dash')\n)\ntrace2 = go.Scatter(\n    x = np.arange(0, len(history.history['val_loss']), 1),\n    y = history.history['val_loss'],\n    mode = 'lines',\n    name = 'Test loss',\n    line = dict(color=('rgb(244, 146, 65)'), width=2)\n)\n\ndata = [trace1, trace2]\nlayout = dict(title = 'Train and Test Loss during training',\n              xaxis = dict(title = 'Epoch number'), yaxis = dict(title = 'Loss'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='training_process')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add one additional data point to align shapes of the predictions and true labels\nprint(X_test.shape)\nprint(working_data.shape)\ny=scaler.transform(working_data.iloc[-1][0].reshape(1,-1))\nprint(y.shape)\nX_test = np.append(X_test, y)\nX_test = np.reshape(X_test, (len(X_test), 1, 1))\n\n# get predictions and then make some transformations to be able to calculate RMSE properly in USD\nprediction = model.predict(X_test)\nprediction_inverse = scaler.inverse_transform(prediction.reshape(-1, 1))\nY_test_inverse = scaler.inverse_transform(Y_test.reshape(-1, 1))\nprediction2_inverse = np.array(prediction_inverse[:,0][1:])\nY_test2_inverse = np.array(Y_test_inverse[:,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    x = np.arange(0, len(prediction2_inverse), 1),\n    y = prediction2_inverse,\n    mode = 'lines',\n    name = 'Predicted labels',\n    line = dict(color=('rgb(244, 146, 65)'), width=2)\n)\ntrace2 = go.Scatter(\n    x = np.arange(0, len(Y_test2_inverse), 1),\n    y = Y_test2_inverse,\n    mode = 'lines',\n    name = 'True labels',\n    line = dict(color=('rgb(66, 244, 155)'), width=2)\n)\n\ndata = [trace1, trace2]\nlayout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted',\n             xaxis = dict(title = 'Day number'), yaxis = dict(title = 'Price, USD'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='results_demonstrating0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_Dates = Daily_Price[len(Daily_Price)-days_from_train:].index\n\ntrace1 = go.Scatter(x=Test_Dates, y=Y_test2_inverse, name= 'Actual Price',\n                   line = dict(color = ('rgb(66, 244, 155)'),width = 2))\ntrace2 = go.Scatter(x=Test_Dates, y=prediction2_inverse, name= 'Predicted Price',\n                   line = dict(color = ('rgb(244, 146, 65)'),width = 2))\ndata = [trace1, trace2]\nlayout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted, by dates',\n             xaxis = dict(title = 'Date'), yaxis = dict(title = 'Price, USD'))\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='results_demonstrating1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nX_test=np.delete(X_test,0,0)\n\nprint(\"1 layer LSTM\")\nprint(\"RMSE:\", sqrt(mean_squared_error(Y_test, regressor.predict(X_test))))\nprint(\"R-squared:\", r2_score(Y_test, regressor.predict(X_test)))\nprint(\"Mean absolute error:\", mean_absolute_error(Y_test, regressor.predict(X_test)))\nprint(\"2 layer LSTM\")\nprint(\"RMSE:\", sqrt(mean_squared_error(Y_test,model.predict(X_test))))\nprint(\"Mean absolute error:\", mean_absolute_error(Y_test, model.predict(X_test)))\nprint(\"R-squared:\", r2_score(Y_test, model.predict(X_test)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}